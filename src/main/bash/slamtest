#! /bin/bash
# SlamTest, version $VERSION$.
# 
# For more information, run `slamtest -h`.

VERSION='$VERSION$'
AUTHOR='jcbrinfo <jcbrinfo@users.noreply.github.com>'
LICENSE='
       Copyright (c) 2016, jcbrinfo <jcbrinfo@users.noreply.github.com>.

       Permission to use, copy, modify, and/or distribute this software for
       any purpose with or without fee is hereby granted, provided that the
       above copyright notice and this permission notice appear in all copies.

       THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANT-
       IES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
       MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
       ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
       WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
       ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
       OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.'

# ##############################################################################
# Paths

# The following paths MUST NOT end with a slash.

readonly TEST_SOURCE_DIRECTORY=src/test/resources
readonly TEST_TARGET_DIRECTORY=target/test

# ##############################################################################
# Exit statuses

readonly E_FAIL=1
readonly E_USAGE=2

# ##############################################################################
# Options

readonly HELP_OPTION=h
readonly LOAD_MODULE_OPTION=l
readonly TEST_CASE_OPTION=t
readonly VERSION_OPTION=v

# The option string for `getopts`.
readonly OPTION_STRING=":\
${HELP_OPTION}${LOAD_MODULE_OPTION}:${TEST_CASE_OPTION}:${VERSION_OPTION}\
"

# ##############################################################################
# Global variables

# The tested command.
tested_command=

# The number of successes.
successes=

# The number of failures.
fails=

# ##############################################################################
# Test execution

##run_test in_path out_path [variant]
# Executes the specified test.
#
# @param in_path the path to the input file
# @param out_path the path to which the output is redirected
# @param variant the additional argument to pass to the tested program
run_test() {
	command -- "${tested_command[@]}" "${@:3}" < "$1" > "$2" 2>&1
}

##test_all
# Executes all the tests.
test_all() {
	local test_case

	for test_case in "${TEST_SOURCE_DIRECTORY}"/in/*; do
		if [ -e "${test_case}" ]; then
			test_one_input "${test_case##*/}"
		fi
	done
}

##test_compare test_name out_dir_name [variant]
# Compares actual and expected outputs of the specified test.
#
# Expects the test has already been executed.
#
# @param test_name the filename of the test
# @param out_dir_name the filename of the output directories
# @param variant the last argument to pass to the tested program
test_compare() {
	local test_name="$1"
	local out_dir_name="$2"
	local variant=("${@:3}")
	local expected="${TEST_SOURCE_DIRECTORY}/${out_dir_name}/${test_name}"
	local actual="${TEST_TARGET_DIRECTORY}/${out_dir_name}/${test_name}"
	local status
	local compare_program=
	local compare_options=()

	if [ -e "${actual}" ]; then
		# `cmp` is unable to compare anything else than regular files.
		if [ -f "${actual}" ] && [ -f "${expected}" ]; then
			compare_program=cmp
			compare_options=(-s)
		elif [ -f "${actual}" ] || [ -f "${expected}" ]; then
			# The behaviour of `diff` (see below) is unpredictable in this edge
			# case. So, we have to handle this case by ourselves.
			add_fail "unexpected output" "${test_name}" "${variant[@]}"
			return
		else
			compare_program=diff
			compare_options=(-r)
		fi
		"${compare_program}" "${compare_options[@]}" -- \
				"${actual}" "${expected}" > /dev/null 2>&1
		status="$?"
		if [ "${status}" = 0 ]; then
			add_success "success" "${test_name}" "${variant[@]}"
		elif [ "${status}" = 1 ]; then
			add_fail "unexpected output" "${test_name}" "${variant[@]}"
		else
			add_fail "internal error: \`${compare_program}\` failed" \
					"${test_name}" "${variant[@]}"
		fi
	else
		add_fail "actual output missing" "${test_name}" "${variant[@]}"
	fi
}

##test_one test_name out_dir_name [variant]
# Executes the specified test and checks the result.
#
# @param test_name the filename of the test
# @param out_dir_name the filename of the output directories
# @param variant the last argument to pass to the tested program
test_one() {
	local test_name="$1"
	local out_dir_name="$2"
	local variant=("${@:3}")
	run_test "${TEST_SOURCE_DIRECTORY}/in/${test_name}" \
			"${TEST_TARGET_DIRECTORY}/${out_dir_name}/${test_name}" \
			"${variant[@]}"
	local status="$?"
	if [ "${status}" != 0 ]; then
		add_fail "exit status not 0: got ${status}" "${test_name}" \
				"${variant[@]}"
	else
		test_compare "$@"
	fi
}

##test_one_input test_name
# Executes all the tests related to the same input file.
#
# @param test_name the name of the input file (the name of the test case)
test_one_input() {
	local test_name="$1"
	local expected_out_path
	local out_dir
	local out_dir_name

	# Does this test case has at least one expected output?
	local has_out=0

	if [ -e "${TEST_SOURCE_DIRECTORY}"/out/"${test_name}" ]; then
		has_out=1
		test_one "${test_name}" out
	fi
	for expected_out_path in "${TEST_SOURCE_DIRECTORY}"/out-*/"${test_name}"; do
		if [ -e "${expected_out_path}" ]; then
			has_out=1
			out_dir="${expected_out_path%"/${test_name}"}"
			out_dir_name="${out_dir##*/}"
			test_one "${test_name}" "${out_dir_name}" "${out_dir_name#out-}"
		fi
	done
	if [ "${has_out}" = 0 ]; then
		add_fail "expected output missing" "${test_name}"
	fi
}

# ##############################################################################
# Display

##add_success message test_name [variant]
# Adds a success.
#
# @param message a short description of the success
# @param test_name the filename of the test
# @param variant the last argument to pass to the tested program
add_success() {
	if [ "$#" = 3 ]; then
		printf -- '- [x] `%s` (`%s`): %s\n' "$2" "$3" "$1"
	else
		printf -- '- [x] `%s`: %s\n' "$2" "$1"
	fi
	successes=$((successes + 1))
}

##add_fail message test_name [variant]
# Add a failure.
#
# @param message a short description of the failure
# @param test_name the filename of the test
# @param variant the last argument to pass to the tested program
add_fail() {
	if [ "$#" = 3 ]; then
		printf -- '- [ ] `%s` (`%s`): %s\n' "$2" "$3" "$1"
	else
		printf -- '- [ ] `%s`: %s\n' "$2" "$1"
	fi
	fails=$((fails + 1))
}

##echo_error message
# Writes the specified error message to the standard error output.
#
# @param message a short description of the error
echo_error() {
	printf "%s: %s\n" "$0" "$1" >&2
}

##echo_summary total sucesses fails
# Writes the summary line.
#
# @param total the total number of tests
# @param successes the number of successes
# @param fails the number of failures
echo_summary() {
	local total="$1"
	local successes="$2"
	local fails="$3"

	printf "%d " "${total}"
	if ((total >= 2)); then
		printf "tests"
	else
		printf "test"
	fi
	printf ", %d " "${successes}"
	if ((successes >= 2)); then
		printf "successes"
	else
		printf "success"
	fi
	printf ", %d " "${fails}"
	if ((fails >= 2)); then
		printf "fails"
	else
		printf "fail"
	fi
	echo .
}

##echo_version
# Writes the version.
echo_version() {
	printf "%s\n" "${VERSION}"
}

# ##############################################################################
# Built-in manual

##echo_help
# Writes the built-in manual.
echo_help() {
	echo "\
NAME
       slamtest — run tests

SYNOPSIS
       $0 [-${LOAD_MODULE_OPTION} <script’s path>] \\
           [-${TEST_CASE_OPTION} <test case name>] [tested_command…]
       $0 -${HELP_OPTION}
       $0 -${VERSION_OPTION}

DESCRIPTION
       SlamTest is a simple BASH script that runs a program against a series
       of inputs and checks that the outputs match the expected ones. This
       script should be invoked from the root directory of the project to
       test. For a explanation of how to describe the tests, see the “INPUT
       FILES” section. For the location of the actual outputs of the tested
       program, see “OUTPUT FILES”.

       The name of each test case reflects the name of the input file used for
       this test case.

OPTIONS
       -${HELP_OPTION}     Display the built-in manual (this manual).

       -${LOAD_MODULE_OPTION} <script’s path>
              Include (“source”) the specified BASH script. For more informa-
              tion on how to use this feature, see the “Redefining how to run
              a test” subsection of the “EXTENDED DESCRIPTION”.

       -${TEST_CASE_OPTION} <test case name>
              Instead of running all test cases found, run only the specified
              one.

              Note: A test case may contain more than one test. For details,
              see “INPUT FILE”.

       -${VERSION_OPTION}     Display the version information.

OPERANDS
       tested_command
              The command to test.

STDIN
       Not used.

INPUT FILES
       <definition directory>
              The directory containing the test’s definitions.
              (“${TEST_SOURCE_DIRECTORY}” by default)

       <definition directory>/in/<test case name>
              The input for the test case named “<test case name>“.

       <definition directory>/out/<test case name>
              The expected output for the test case named “<test case name>”,
              when the tested command is invoked without any additional argu-
              ment.

       <definition directory>/out-<arg>/<test case name>
              The expected output for the test case named “<test case name>”,
              when the “<arg>” argument is appended to the tested command.

       For each test case found in “<definition directory>/in”, SlamTest looks
       for any file with the same name in “<definition directory>/out” and/or
       “<definition directory>/out-*”. For each output file found, a test is
       run using the found file as the expected output. When the expected
       output is located in a “<definition directory>/out-<arg>” directory,
       “<arg>” is added as an argument to the end of the tested command.

ENVIRONMENT VARIABLES
       None.

STDOUT
       Except when run using the “-h” or “-v” option, a list the results is
       written. This list is formatted as task list using the GitHub Flavored
       Markdown. Then, a summary line of the form
       “<t> tests, <s> sucesses, <f> fails.” is written.

STDERR
       The standard error output of the script is reserved for writting diag-
       nostic messages when SlamTest is incorrectly used.

OUTPUT FILES
       <target directory>
              The directory containing the files generated during the tests.
              (“${TEST_TARGET_DIRECTORY}” by default)

       <target directory>/out/<test case name>
              The actual output for the test case named “<test case name>”,
              when the tested command is invoked without any additional argu-
              ment. Compared against
              “<definition directory>/out/<test case name>”.

       <target directory>/out-<arg>/<test case name>
              The actual output for the test case named “<test case name>”,
              when the “<arg>” argument is appended to the tested command.
              Compared against
              “<definition directory>/out-<arg>/<test case name>”.

       Note: Even if this script creates the required directories automatica-
       ly, it does not use the more robust cross-platform way to do this: it
       simply uses “mkdir -p”. If your build system already offer a more por-
       table way to create missing directories (like Autoconf and Automake),
       rely on it instead. For more details, see <http://bit.ly/1VeuAUJ>.

EXTENDED DESCRIPTION
   Redefining how to run a test
       By default, SlamTest runs the specified command by redirecting the
       standard input and outputs, and append an additional argument when
       needed (see “INPUT FILES”). However, there are some situation were the
       tested program need to be invoked differently. May be the input file
       are actualy directories, may be the program requires the filenames as
       arguments… To handle these cases, SlamTest has the “-${LOAD_MODULE_OPTION}” that takes the
       path of a BASH script that defines the “run_test” function.

       The “run_test” is called to run each test and takes at most 3
       arguments, with the last one being optional. The arguments are,
       respectively:

       1. The path to the input file.

       2. The path to which the output is redirected.

       3. The additional argument to pass to the tested program (see “INPUT
          FILES”).

       The list of the arguments passed to SlamTest that are not options (that
       is the tested command if you do not redefine “run_test”) is stored as
       an array in the “tested_command” global variable.

       Here is the default definition of “run_test”:

              run_test() {
	              command -- \"\${tested_command[@]}\" \"\${@:3}\" \\
	                      < \"\$1\" > \"\$2\" 2>&1
              }


       Note: The script specified to the “-${LOAD_MODULE_OPTION}” is included (“sourced”) directly
       by SlamTest’s script. So, avoid defining any global variable (or BASH
       option) other than “run_test” in the included script in order to avoid
       disturbing the inner workings of main script.

EXIT STATUS
       0      All tests pass.

       1      At least one test fails.

       2      The script is not used correctly.

EXAMPLES
       $0 java -cp target/main com.example.MyProgram
              Test the command “java -cp target/main com.example.MyProgram”,
              that is the usual command to run the Java class
              “target/main/com/example/MyProgram.class”.

AUTHOR
       ${AUTHOR}

LICENSING${LICENSE}

SEE ALSO
       comm, cmp, diff

       The “README.md” file of the SlamTest’s project.\
"
}

# ##############################################################################
# Errors

##raise_invalid_option option_name
# Raise an error about an invalid option.
#
# @param option_name the name of the option (without the dash)
raise_invalid_option() {
	raise_usage_error "illegal option: -$1"
}

##raise_missing_argument option_name
# Raise an error about a missing option-argument.
#
# @param option_name the name of the option (without the dash)
raise_missing_argument() {
	raise_usage_error "option -$1 requires an argument"
}

##raise_missing_command
# Raise an error because the command to test is missing.
raise_missing_command() {
	raise_usage_error "command missing"
}

##raise_usage_error message
# Raise an error concerning the arguments passed to the script.
#
# @param message a short description of the error
raise_usage_error() {
	echo_error "$1"
	printf "For more information, run “%s -%s”.\n" "$0" "${HELP_OPTION}"
	exit "${E_USAGE}"
}

# ##############################################################################
# Others

##prepare_target
# Creates the directories for the generated files.
prepare_target() {
	if [ -e "${TEST_SOURCE_DIRECTORY}/out" ]; then
		mkdir -p -- "${TEST_TARGET_DIRECTORY}/out"
	fi
	for out_dir in "${TEST_SOURCE_DIRECTORY}"/out-*; do
		if [ -e "${out_dir}" ]; then
			mkdir -p -- "${TEST_TARGET_DIRECTORY}/${out_dir##*/}"
		fi
	done
}

##load_module script_path
# Loads (“sources”) the specified BASH script.
#
# @param script_path the path to the script
load_module() {
	. "$1"
}

##main arguments…
# The main routine.
#
# @param arguments the arguments passed to the program
main() {
	local total
	local option_name
	local module_loaded=0
	local test_case=

	while getopts "${OPTION_STRING}" option_name; do
		case "${option_name}" in
		"${HELP_OPTION}")
			echo_help
			return
			;;
		"${LOAD_MODULE_OPTION}")
			load_module "${OPTARG}"
			module_loaded=1
			;;
		"${TEST_CASE_OPTION}")
			test_case="${OPTARG}"
			;;
		"${VERSION_OPTION}")
			echo_version
			return
			;;
		\?)
			raise_invalid_option "${OPTARG}"
			;;
		:)
			raise_missing_argument "${OPTARG}"
			;;
		esac
	done
	shift $((OPTIND - 1))
	tested_command=("$@")

	if [ "${module_loaded}" = 0 ] && [ "${#tested_command}" = 0 ]; then
		raise_missing_command
	fi

	successes=0
	fails=0
	prepare_target
	if [ -z "${test_case}" ]; then
		test_all
	else
		test_one_input "${test_case}"
	fi

	total=$((successes + fails))
	echo
	echo_summary "${total}" "${successes}" "${fails}"

	if ((fails > 0)); then
		exit "${E_FAIL}"
	fi
}

main "$@"
